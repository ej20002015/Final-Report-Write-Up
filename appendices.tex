\begin{appendices}

%
% The first appendix must be "Self-appraisal".
%
\chapter{Self-appraisal}

<This appendix should contain everything covered by the 'self-appraisal' criterion in the mark scheme. Although there is no length limit for this section, 2---4 pages will normally be sufficient. The format of this section is not prescribed, but you may like to organise your discussion into the following sections and subsections.>

\section{Critical self-evaluation}

\section{Personal reflection and lessons learned}

\section{Legal, social, ethical and professional issues}

<Refer to each of these issues in turn. If one or more is not relevant to your project, you should still explain {\em why} you think it was not relevant.>

\subsection{Legal issues}

\subsection{Social issues}

\subsection{Ethical issues}

\subsection{Professional issues}


%
% Any other appendices you wish to use should come after "Self-appraisal". You can have as many appendices as you like.
%
\chapter{External Material} \label{ExternalMaterial}
<This appendix should provide a brief record of materials used in the solution that are not the student's own work. Such materials might be pieces of codes made available from a research group/company or from the internet, datasets prepared by external users or any preliminary materials/drafts/notes provided by a supervisor. It should be clear what was used as ready-made components and what was developed as part of the project. This appendix should be included even if no external materials were used, in which case a statement to that effect is all that is required.>

Three types of external material were used in my solution: software libraries, an implementation of the ACES tone mapping operator, and 3D Models.

\section{Software Libraries} \label{SoftwareLibraries}

The libraries used in my renderer are listed below. For each one, a description is provided, along with a link. Note that the separation between my code and the external libraries is very clear in the code base, with all libraries being present under the \mintinline{bash}|Application/Vendor| directory.

\vspace{20pt}

\noindent\begin{tabular}{|m{5em}|m{28em}|m{8em}|}
	\hline
	\textbf{Library Name} & \textbf{Description} & \textbf{Link} \\
	\hline\hline
	GLFW & A cross-platform utility library that provides windowing, OpenGL contexts and retrieves input events & \url{https://www.glfw.org/} \\
	\hline
	Glad & A library for loading pointers to the OpenGL functions & \url{https://glad.dav1d.de/} \\
	\hline
	GLM	& A maths library specifically designed for use with OpenGL & \url{https://github.com/g-truc/glm} \\
	\hline
	spdlog & A fast logging library & \url{https://github.com/gabime/spdlog} \\
	\hline
	stb\_image & An image loading library that is used when creating textures & \url{https://github.com/nothings/stb/blob/master/stb_image.h} \\
	\hline
	assimp & A library to import 3D models of various different file types & \url{https://github.com/assimp/assimp} \\
	\hline
\end{tabular}

\section{ACES Tone Mapping Operator} \label{ACESExternalMaterial}

The implementation of the ACES tone mapping operator, which is given in Listing \ref{ls:ACES}, is a slightly modified version of Stephen Hill's code. His code can be accessed via the following link: \url{https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl}

\section{3D Models}


%
% Other appendices can be added here following the same pattern as above.
%
\chapter{Mathematical Notation} \label{MathematicalNotation}

\begin{center}
	\begin{tabular}{ c c }
		\hline
		\begin{math}\vect{n}\end{math} & Normal vector \\
		\begin{math}\vect{l}\end{math} & Light direction \\
		\begin{math}\vect{v}\end{math} & View vector \\
		\begin{math}\vect{h}\end{math} & Half vector \\
		\begin{math}\vect{a}\cdot\vect{b}\end{math} & The dot product of vectors \begin{math}\vect{a}\end{math} and \begin{math}\vect{b}\end{math} \\
		\begin{math}\norm{\vect{a}}\end{math} & The norm of vector \begin{math}\vect{a}\end{math} \\
		\begin{math}\abs{x}\end{math} & The absolute value of \begin{math}x\end{math} \\
		\begin{math}x^+\end{math} & Clamp \begin{math}x\end{math} to \begin{math}0\end{math} if \begin{math}x<0\end{math} \\
		\begin{math}\mathcal{X}^+(x)\end{math} & Returns 1 if \begin{math}x > 0\end{math}, else returns 0 \\
		\begin{math}lerp(x, y, t)\end{math} & Linearly interpolates between \begin{math}x\end{math} and \begin{math}y\end{math} by the interpolant \begin{math}t\end{math}: \begin{math}lerp(x, y, t) = x(1 - t) + yt\end{math} \\
		\hline
	\end{tabular}
\end{center}

\chapter{Shader Code} \label{ShaderCode}

All the shader code can be accessed in the code base under the \mintinline{bash}|Application/Assets/Shaders| directory. The code is also given below as it is useful to be able to view the end-to-end process of shading. As is demanded by most graphics APIs, each shader program given below is split into a vertex and fragment shader.

\section{Blinn-Phong Shader}

\subsection{Vertex Shader}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos,
breaklines
]
{glsl}
#version 460 core

// ATTRIBUTES

layout (location = 0) in vec3 a_position;
layout (location = 1) in vec3 a_normal;
layout (location = 2) in vec2 a_textureCoordinates;
layout (location = 3) in vec3 a_tangent;
layout (location = 4) in vec3 a_bitangent;

// UNIFORMS

uniform mat4 u_transform;
uniform mat4 u_projectionViewMatrix;

// OUTPUTS

struct VertexOutput
{
	vec3 worldPosition;
	vec3 normal;
	vec2 textureCoordinates;
	mat3 TBN;
};

out VertexOutput vertex_output;

// FUNCTIONS

void main()
{
	vertex_output.worldPosition = vec3(u_transform * vec4(a_position, 1.0f));
	vertex_output.normal = normalize(vec3(transpose(inverse(u_transform)) * vec4(a_normal, 0.0f)));
	vertex_output.textureCoordinates = a_textureCoordinates;
	
	vec3 normalTransformed = normalize(vec3(u_transform * vec4(a_normal, 0.0f)));
	vec3 tangentTransformed = normalize(vec3(u_transform * vec4(a_tangent, 0.0f)));
	vec3 bitangentTransformed = normalize(vec3(u_transform * vec4(a_bitangent, 0.0f)));
	vertex_output.TBN = mat3(tangentTransformed, bitangentTransformed, normalTransformed);
	
	gl_Position = u_projectionViewMatrix * u_transform * vec4(a_position, 1.0f);
}
\end{minted}

\subsection{Fragment Shader}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos,
breaklines
]
{glsl}
#version 460 core

// INPUTS FROM VERTEX SHADER

struct VertexOutput
{
	vec3 worldPosition;
	vec3 normal;
	vec2 textureCoordinates;
	mat3 TBN;
};

in VertexOutput vertex_output;

// UNIFORMS

// Material

struct Material
{
	vec4 diffuseColor;
	vec3 specularColor;
	sampler2D diffuseMap;
	sampler2D specularMap;
	sampler2D normalMap;
	float shininess;
	
	bool useNormalMap;
};

uniform Material u_material;

// Point lights

struct PointLight
{
	vec3 worldPosition;
	vec3 diffuseComponent;
	vec3 specularComponent;
	float lightRadius;
};

const uint MAX_NUMBER_OF_POINT_LIGHTS = 128;
uniform PointLight u_pointLights[MAX_NUMBER_OF_POINT_LIGHTS];
uniform uint u_pointLightNumber;

uniform vec3 u_viewPosition;

// OUTPUTS

layout(location = 0) out vec4 o_fragColor;

// CONSTANTS

const vec3 LIGHT_AMBIENT = vec3(0.02f);

// GLOBAL DATA

vec3 g_normal;
vec3 g_viewDirection;
vec3 g_diffuseMaterialValue;
vec3 g_specularMaterialValue;

// FUNCTIONS

vec3 getNormalisedSurfaceNormal()
{
	if (u_material.useNormalMap)
	{
		vec4 sampleFromNormalMap = texture(u_material.normalMap, vertex_output.textureCoordinates);
		vec3 sampledNormal = (sampleFromNormalMap.rgb * 2.0f) - 1.0f;
		vec3 sampledNormalInWorldSpace = vertex_output.TBN * sampledNormal;
		return normalize(sampledNormalInWorldSpace);
	}
	else
	return normalize(vertex_output.normal);
}

float calculatePointLightAttenuationFactor(float lightDistance, float lightRadius)
{
	const float lightSize = 0.01f;
	const uint n = 4;
	
	// Restrict the minimum value of the denominator to 0.01 * 0.01 to avoid the value
	// exploding or having divide by zero errors
	float inverseSquaredDistance = 1.0f / pow(max(lightDistance, lightSize), 2.0f);
	
	// Use a windowing function to cutoff the attenuation value to 0 at large distances
	
	float lightDistanceNOverLightRadiusN = 1.0f - pow(lightDistance / lightRadius, n);
	float windowingFunctionValue = pow(clamp(lightDistanceNOverLightRadiusN, 0.0f, 1.0f), 2.0f);
	
	return min(inverseSquaredDistance * windowingFunctionValue, 1.0f);
}

vec3 calculateDiffuseContribution(vec3 lightDirection, vec3 attenuatedLightDiffuseComponent)
{
	float lightIncidentDiffuseFactor = max(dot(lightDirection, g_normal), 0.0f);
	return (g_diffuseMaterialValue * lightIncidentDiffuseFactor) * attenuatedLightDiffuseComponent;
}

vec3 calculateSpecularContribution(vec3 lightDirection, vec3 attenuatedLightSpecularComponent)
{
	vec3 halfVector = normalize(g_viewDirection + lightDirection);
	float lightReflectedSpecularFactor = pow(max(dot(halfVector, g_normal), 0.0f), u_material.shininess);
	return (g_specularMaterialValue * lightReflectedSpecularFactor) * attenuatedLightSpecularComponent;
}

vec3 gammaCorrectColor(vec3 color)
{
	vec3 SRGBEncodedHigher = (1.055f * pow(color, vec3(1.0f / 2.4f))) - 0.055f;
	vec3 SRGBEncodedLower = 12.92f * color;
	float rSRGBEncoded = (color.r > 0.0031308f) ? SRGBEncodedHigher.r : SRGBEncodedLower.r;
	float gSRGBEncoded = (color.g > 0.0031308f) ? SRGBEncodedHigher.g : SRGBEncodedLower.g;
	float bSRGBEncoded = (color.b > 0.0031308f) ? SRGBEncodedHigher.b : SRGBEncodedLower.b;
	return vec3(rSRGBEncoded, gSRGBEncoded, bSRGBEncoded);
}

void main()
{
	vec3 color;
	g_normal = getNormalisedSurfaceNormal();
	g_viewDirection = normalize(u_viewPosition - vertex_output.worldPosition);
	
	vec4 diffuseMaterialValueWithAlpha = texture(u_material.diffuseMap, vertex_output.textureCoordinates) * u_material.diffuseColor;
	float alpha = diffuseMaterialValueWithAlpha.a;
	
	g_diffuseMaterialValue = diffuseMaterialValueWithAlpha.rgb;
	g_specularMaterialValue = texture(u_material.specularMap, vertex_output.textureCoordinates).rgb * u_material.specularColor;
	
	// Calculate ambient contribution
	
	color = g_diffuseMaterialValue * LIGHT_AMBIENT;
	
	// Calculate diffuse and specular contribution for each light
	
	for (uint i = 0; i < u_pointLightNumber; i++)
	{
		PointLight pointLight = u_pointLights[i];
		vec3 lightDirection = normalize(pointLight.worldPosition - vertex_output.worldPosition);
		
		float lightDistance = length(pointLight.worldPosition - vertex_output.worldPosition);
		float attenuationFactor = calculatePointLightAttenuationFactor(lightDistance, pointLight.lightRadius);
		
		color += calculateDiffuseContribution(lightDirection, pointLight.diffuseComponent * attenuationFactor);
		color += calculateSpecularContribution(lightDirection, pointLight.specularComponent * attenuationFactor);
	}
	
	o_fragColor = vec4(gammaCorrectColor(color), alpha);
}
\end{minted}

\section{Physically Based Shaders}

\subsection{PBS Vertex Shader}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos,
breaklines
]
{glsl}
#version 460 core

// ATTRIBUTES

layout (location = 0) in vec3 a_position;
layout (location = 1) in vec3 a_normal;
layout (location = 2) in vec2 a_textureCoordinates;
layout (location = 3) in vec3 a_tangent;
layout (location = 4) in vec3 a_bitangent;

// UNIFORMS

uniform mat4 u_transform;
uniform mat4 u_projectionViewMatrix;

// OUTPUTS

struct VertexOutput
{
	vec3 worldPosition;
	vec3 normal;
	vec2 textureCoordinates;
	mat3 TBN;
};

out VertexOutput vertex_output;

// FUNCTIONS

void main()
{
	vertex_output.worldPosition = vec3(u_transform * vec4(a_position, 1.0f));
	vertex_output.normal = normalize(vec3(transpose(inverse(u_transform)) * vec4(a_normal, 0.0f)));
	vertex_output.textureCoordinates = a_textureCoordinates;
	
	vec3 normalTransformed = normalize(vec3(u_transform * vec4(a_normal, 0.0f)));
	vec3 tangentTransformed = normalize(vec3(u_transform * vec4(a_tangent, 0.0f)));
	vec3 bitangentTransformed = normalize(vec3(u_transform * vec4(a_bitangent, 0.0f)));
	vertex_output.TBN = mat3(tangentTransformed, bitangentTransformed, normalTransformed);
	
	gl_Position = u_projectionViewMatrix * u_transform * vec4(a_position, 1.0f);
}
\end{minted}

\subsection{PBS Fragment Shader}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos,
breaklines
]
{glsl}
#version 460 core

// INPUTS FROM VERTEX SHADER

struct VertexOutput
{
	vec3 worldPosition;
	vec3 normal;
	vec2 textureCoordinates;
	mat3 TBN;
};

in VertexOutput vertex_output;

// UNIFORMS

// Material

struct Material
{
	vec4 baseColor;
	float roughness;
	float metalness;
	sampler2D baseColorMap;
	sampler2D roughnessMap;
	sampler2D metalnessMap;
	sampler2D normalMap;
	
	bool useNormalMap;
};

uniform Material u_material;

// Point lights

struct PointLight
{
	vec3 worldPosition;
	vec3 lightColor;
	float luminousPower;
	float lightRadius;
};

const uint MAX_NUMBER_OF_POINT_LIGHTS = 128;
uniform PointLight u_pointLights[MAX_NUMBER_OF_POINT_LIGHTS];
uniform uint u_pointLightNumber;

uniform vec3 u_viewPosition;

uniform float u_exposure;

// OUTPUTS

layout(location = 0) out vec4 o_fragColor;

// CONSTANTS

const vec3 F0_FOR_DIELECTRICS = vec3(0.04f);
const float PI = 3.14159265359;

// GLOBAL DATA

struct Directions
{
	vec3 normal;
	vec3 viewDirection;
};

Directions g_directions;

struct DotProducts
{
	float nDotV;
};

DotProducts g_dotProducts;

struct MaterialProperties
{
	vec3 baseColor;
	float alpha;
	float roughness;
	float metalness;
	
	vec3 f0;
};

MaterialProperties g_materialProperties;

// FUNCTIONS

/*
Used the Sclick approximation to calculate the Fresnel reflectance
*/
vec3 calculateFresnelSchlickApproximation(vec3 f0, float u)
{
	return f0 + (1 - f0) * pow((1 - u), 5.0f);
}

/*
Used the Smith height-correlated masking-shadowing function.

As pointed out by Lagarde, using a combination of Smith and the GGX NDF
in the specular (surface reflection) BRDF term means optimisations can be made.

Namely, G(l,v) / (4 * |n.l| * |n.v|) can be simplified. Hammon gives an accurate 
approximation for the above term. This approximation is being calculated in the function.

See https://www.gdcvault.com/play/1024478/PBR-Diffuse-Lighting-for-GGX
*/
float calculateHammonSmithMaskingSpecularDenominatorAppoximation(float nDotL)
{
	float alpha = g_materialProperties.roughness * g_materialProperties.roughness;
	float x = 2.0f * abs(nDotL) * abs(g_dotProducts.nDotV);
	float y = abs(nDotL) + abs(g_dotProducts.nDotV);
	return 1.0f / (2.0f * mix(x, y, alpha));
}

/*
Use the GGX (Trowbridge-Reitz) distribution for the NDF.

Also used the Disney mapping of alpha = roughness * roughness, where roughness
then gives a perceptually linear change from [0, 1].
*/
float calculateGGXDistribution(float nDotH)
{
	float alpha = g_materialProperties.roughness * g_materialProperties.roughness;
	float alpha2 = alpha * alpha;
	float x = 1 + (nDotH * nDotH * (alpha2 - 1.0f));
	return alpha2 / (PI * x * x);
}

vec3 getNormalisedSurfaceNormal()
{
	if (u_material.useNormalMap)
	{
		vec4 sampleFromNormalMap = texture(u_material.normalMap, vertex_output.textureCoordinates);
		vec3 sampledNormal = (sampleFromNormalMap.rgb * 2.0f) - 1.0f;
		vec3 sampledNormalInWorldSpace = vertex_output.TBN * sampledNormal;
		return normalize(sampledNormalInWorldSpace);
	}
	else
	return normalize(vertex_output.normal);
}

float calculatePointLightAttenuationFactor(float lightDistance, float lightRadius)
{
	const float lightSize = 0.01f;
	const uint n = 4;
	
	// Restrict the minimum value of the denominator to 0.01 * 0.01 to avoid the value
	// exploding or having divide by zero errors
	float inverseSquaredDistance = 1.0f / pow(max(lightDistance, lightSize), 2.0f);
	
	// Use a windowing function to cutoff the attenuation value to 0 at large distances
	
	float lightDistanceNOverLightRadiusN = 1.0f - pow(lightDistance / lightRadius, n);
	float windowingFunctionValue = pow(clamp(lightDistanceNOverLightRadiusN, 0.0f, 1.0f), 2.0f);
	
	return min(inverseSquaredDistance * windowingFunctionValue, 1.0f);
}

vec3 calculatePointLightContribution(const PointLight pointLight)
{
	// Calculate the incoming radiance from the point light
	
	float lightDistance = length(pointLight.worldPosition - vertex_output.worldPosition);
	float lightAttenuationFactor = calculatePointLightAttenuationFactor(lightDistance, pointLight.lightRadius);
	
	float luminousIntensity = pointLight.luminousPower / (4.0f * PI);
	vec3 lightRadiance = pointLight.lightColor * luminousIntensity * lightAttenuationFactor;
	
	// Initialise values
	
	vec3 lightDirection = normalize(pointLight.worldPosition - vertex_output.worldPosition);
	vec3 halfVector = normalize(g_directions.viewDirection + lightDirection);
	
	float nDotL = dot(g_directions.normal, lightDirection);
	float hDotL = dot(halfVector, lightDirection);
	float nDotH = dot(g_directions.normal, halfVector);
	
	// Specular (surface reflection) term
	
	// fresnelReflectance is also the specularTermContribution
	vec3 fresnelReflectance = calculateFresnelSchlickApproximation(g_materialProperties.f0, max(hDotL, 0.0f));
	float hammonSmithMaskingSpecularDenominatorApproximation = calculateHammonSmithMaskingSpecularDenominatorAppoximation(nDotL);
	float NDF = calculateGGXDistribution(nDotH);
	
	vec3 specularTerm = fresnelReflectance * hammonSmithMaskingSpecularDenominatorApproximation * NDF;
	
	// Diffuse (sub-surface reflection) term
	
	vec3 diffuseTermContribution = (vec3(1.0f) - fresnelReflectance) * (1.0f - g_materialProperties.metalness);
	vec3 diffuseTerm = diffuseTermContribution * (g_materialProperties.baseColor / PI);
	
	// Integrate the reflectance equation with respect to this light
	
	vec3 BRDFValue = diffuseTerm + specularTerm;
	return BRDFValue * lightRadiance * max(nDotL, 0.0f);
}

void main()
{
	// Initialise global values
	
	g_directions.normal = getNormalisedSurfaceNormal();
	g_directions.viewDirection = normalize(u_viewPosition - vertex_output.worldPosition);
	
	g_dotProducts.nDotV = dot(g_directions.normal, g_directions.viewDirection);
	
	vec4 baseColorWithAlpha = texture(u_material.baseColorMap, vertex_output.textureCoordinates) * u_material.baseColor;
	g_materialProperties.baseColor = baseColorWithAlpha.rgb;
	g_materialProperties.alpha = baseColorWithAlpha.a;
	g_materialProperties.roughness = texture(u_material.roughnessMap, vertex_output.textureCoordinates).r * u_material.roughness;
	g_materialProperties.metalness = texture(u_material.metalnessMap, vertex_output.textureCoordinates).r * u_material.metalness;
	g_materialProperties.f0 = mix(F0_FOR_DIELECTRICS, g_materialProperties.baseColor, g_materialProperties.metalness);
	
	// Solve the reflectance equation by evaluating the contribution of each point light
	
	vec3 fragmentColor = vec3(0.0f);
	
	for (uint i = 0; i < u_pointLightNumber; i++)
	fragmentColor += calculatePointLightContribution(u_pointLights[i]);
	
	// Apply a rudimentary ambient term
	
	vec3 ambientTerm = vec3(0.05f) * g_materialProperties.baseColor;
	fragmentColor += ambientTerm;
	
	// Output the shaded color
	
	o_fragColor = vec4(fragmentColor, g_materialProperties.alpha);
}
\end{minted}

\subsection{Post Processing Vertex Shader}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos,
breaklines
]
{glsl}
#version 460 core

// ATTRIBUTES

layout (location = 0) in vec2 a_position;
layout (location = 1) in vec2 a_textureCoordinates;

// OUTPUTS

struct VertexOutput
{
	vec2 textureCoordinates;
};

out VertexOutput vertex_output;

// FUNCTIONS

void main()
{
	vertex_output.textureCoordinates = a_textureCoordinates;
	gl_Position = vec4(a_position, 0.0f, 1.0f);
}
\end{minted}

\subsection{Post Processing Fragment Shader}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos,
breaklines
]
{glsl}
#version 460 core

// INPUTS FROM VERTEX SHADER

struct VertexOutput
{
	vec2 textureCoordinates;
};

in VertexOutput vertex_output;

// UNIFORMS

uniform sampler2D u_inputTexture;
uniform float u_exposure;

// OUTPUTS

layout(location = 0) out vec4 o_fragColor;

// FUNCTIONS

/*
ACES Tone Mapping

Curve adapted from: https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl
*/
vec3 applyToneMapping(vec3 color)
{
	mat3 inputMatrix = mat3
	(
	0.59719f,  0.07600f,  0.02840f,
	0.35458f,  0.90834f,  0.13383f,
	0.04823f,  0.01566f,  0.83777f
	);
	
	mat3 outputMatrix = mat3
	(
	1.60475f, -0.10208f, -0.00327f,
	-0.53108f,  1.10813f, -0.07276f,
	-0.07367f, -0.00605f,  1.07602f
	);
	
	color = inputMatrix * color;
	vec3 a = color * (color + 0.0245786f) - 0.000090537f;
	vec3 b = color * (0.983729f * color + 0.4329510f) + 0.238081f;
	color = a / b;
	
	return clamp(outputMatrix * color, 0.0f, 1.0f);
}

vec3 gammaCorrectColor(vec3 color)
{
	vec3 SRGBEncodedHigher = (1.055f * pow(color, vec3(1.0f / 2.4f))) - 0.055f;
	vec3 SRGBEncodedLower = 12.92f * color;
	float rSRGBEncoded = (color.r > 0.0031308f) ? SRGBEncodedHigher.r : SRGBEncodedLower.r;
	float gSRGBEncoded = (color.g > 0.0031308f) ? SRGBEncodedHigher.g : SRGBEncodedLower.g;
	float bSRGBEncoded = (color.b > 0.0031308f) ? SRGBEncodedHigher.b : SRGBEncodedLower.b;
	return vec3(rSRGBEncoded, gSRGBEncoded, bSRGBEncoded);
}

void main()
{
	vec4 inputColor = texture(u_inputTexture, vertex_output.textureCoordinates);
	float alpha = inputColor.a;
	
	// Apply exposure, tone mapping and gamma correction
	
	inputColor *= u_exposure;
	
	o_fragColor = vec4(gammaCorrectColor(applyToneMapping(inputColor.rgb)), alpha);
}
\end{minted}

\end{appendices}
